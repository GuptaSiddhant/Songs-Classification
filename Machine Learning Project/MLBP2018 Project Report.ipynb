{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Music Genre of Songs using Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precise _summary_ of the whole report, previews the contents and results. Must be a single paragraph between 100 and 200 words.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1. Background\n",
    "Aalto University offers a mandatory and introductory course for Machine Learning, known as Machine Learning Basic Principles. The course deliverables include a Data Analysis Project. The Project can be done alone or in a team of two students; and it shall be done using the Python language in Jupyter Notebook IDE.\n",
    "\n",
    "### 1.2. Problem Statement\n",
    "For Autumn 2018, the Data Analysis Project task participating students to create a music-genre classification algorithm. The data analysis project involves the design of a complete machine learning solution. In particular, the project revolves around the task of identifying the music genre of songs. \n",
    "\n",
    "### 1.3. Motivation\n",
    "\n",
    "### 1.4. Desctiption of Contents\n",
    "\n",
    "### 1.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Background, problem statement, motivation, many references, description of\n",
    "contents. Introduces the reader to the topic and the broad context within which your\n",
    "research/project fits*\n",
    "\n",
    "*- What do you hope to learn from the project?*\n",
    "*- What question is being addressed?*\n",
    "*- Why is this task important? (motivation)*\n",
    "\n",
    "*Keep it short (half to 1 page).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Briefly describe data (class distribution, dimensionality) and how will it affect\n",
    "classification. Visualize the data. Donâ€™t focus too much on the meaning of the features,\n",
    "unless you want to.*\n",
    "\n",
    "*- Include histograms showing class distribution.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gs/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/gs/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Load the data and cleanup\n",
    "dfx = pd.read_csv(\"train_data.csv\", header = None)\n",
    "dfy = pd.read_csv(\"train_labels.csv\" , header= None)\n",
    "dftest =  pd.read_csv(\"test_data.csv\", header = None)\n",
    "## Create Label List\n",
    "Y_train=[]\n",
    "for m in dfy.as_matrix().tolist():\n",
    "    Y_train += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Test and Train data\n",
    "np_scaled_train = preprocessing.quantile_transform(dfx)\n",
    "X_train = pd.DataFrame(np_scaled_train)\n",
    "\n",
    "np_scaled_test = preprocessing.quantile_transform(dftest)\n",
    "X_test = pd.DataFrame(np_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "corr_matrix = X_train.corr()\n",
    "corr_matrix_absolute = X_train.corr().abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*- Explain your whole approach (you can include a block diagram showing the steps in your process).* \n",
    "\n",
    "*- What methods/algorithms, why were the methods chosen. *\n",
    "\n",
    "*- What evaluation methodology (cross CV, etc.).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reduction using Upper Triangular Matrix from Corelation Matrix\n",
    "upper_matrix = corr_matrix_absolute.where(np.triu(np.ones(corr_matrix_absolute.shape), k=1).astype(np.bool))\n",
    "to_drop_index = [column for column in upper_matrix.columns if any(upper_matrix[column] > 0.90)]\n",
    "\n",
    "X_train_reduced = X_train.drop(X_train.columns[to_drop_index], axis=1)\n",
    "X_test_reduced = X_test.drop(X_test.columns[to_drop_index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data1: 0.6552830621132248\n",
      "Best C: 10\n",
      "Best Kernel: rbf\n",
      "Best Gamma: 0.01\n"
     ]
    }
   ],
   "source": [
    "## WARNING - Do not run this block as it normally takes 2-5 hours to execute. \n",
    "## This block exist only to find best score, kernel, gamma and other values for SVM method used in next block. \n",
    "## Running this block is not required for the purpose of making model & predicting outcomes.\n",
    "\n",
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000,10000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000,10000], 'gamma': [0.1,0.01,0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "clf = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "clf.fit(X_train_reduced, Y_train) \n",
    "print('Best score for data1:', clf.best_score_) \n",
    "print('Best C:',clf.best_estimator_.C) \n",
    "print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ML Model with SVC\n",
    "model = SVC(kernel = 'rbf', C = 10,gamma=0.01, probability= True).fit(X_train_reduced, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Predictions using Model for both Accuracy and Log-Loss\n",
    "model_predictions_accuracy = model.predict(X_test_reduced)\n",
    "model_predictions_log_loss = model.predict_proba(X_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summarize the results of the experiments without discussing their implications.*\n",
    "\n",
    "*- Include both performance measures (accuracy and LogLoss).*\n",
    "\n",
    "*- How does it perform on kaggle compared to the train data.*\n",
    "\n",
    "*- Include a confusion matrix.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Predictions to File\n",
    "\n",
    "## Accuracy\n",
    "np.savetxt(\"accuracy_solution.csv\", \n",
    "           np.dstack((np.arange(1, model_predictions_accuracy.size+1),model_predictions_accuracy))[0],\n",
    "           delimiter=',', comments=\"\", fmt='%i,%i',\n",
    "           header=\"Sample_id,Sample_label\")\n",
    "\n",
    "## Log_loss\n",
    "sample_id_column = np.zeros((X_test_reduced.shape[0],1), dtype=int)\n",
    "for i in range (X_test_reduced.shape[0]): \n",
    "    sample_id_column[i] = i+1\n",
    "log_loss_solution = np.hstack((sample_id_column, model_predictions_log_loss))\n",
    "np.savetxt(\"log_loss_solution.csv\", log_loss_solution, \n",
    "           delimiter=',', comments=\"\", fmt=','.join(['%i'] + ['%1.10f']*10),\n",
    "           header=\"Sample_id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9,Class_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpret and explain your results *\n",
    "\n",
    "*- Discuss the relevance of the performance measures (accuracy and LogLoss) for\n",
    "imbalanced multiclass datasets. *\n",
    "\n",
    "*- How the results relate to the literature. *\n",
    "\n",
    "*- Suggestions for future research/improvement. *\n",
    "\n",
    "*- Did the study answer your questions? *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List of all the references cited in the document*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "*Any additional material needed to complete the report can be included here. For example, if you want to keep  additional source code, additional images or plots, mathematical derivations, etc. The content should be relevant to the report and should help explain or visualize something mentioned earlier. **You can remove the whole Appendix section if there is no need for it.** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
